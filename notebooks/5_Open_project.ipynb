{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score, fbeta_score\n",
    "\n",
    "colors = ['#648E9C', '#9CB1BC', '#C5D4DE', '#E8F1F4']\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot samples\n",
    "def plot_samples(images, N=5):\n",
    "    ps = random.sample(range(0, images.shape[0]), N**2)\n",
    "    f, axarr = plt.subplots(N, N, figsize=(10, 10))\n",
    "    p = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            im = images[ps[p]].transpose(1, 2, 0)\n",
    "            im = im / 2 + 0.5  # Unnormalize the image\n",
    "            axarr[i, j].imshow(im)\n",
    "            axarr[i, j].axis('off')\n",
    "            p += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_predictions(predicted_batch, label_batch):\n",
    "    pred = predicted_batch.argmax(dim=1, keepdim=True)\n",
    "    return pred.eq(label_batch.view_as(pred)).sum().item()\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    return total_params, trainable_params, non_trainable_params\n",
    "\n",
    "def train_epoch(epoch, train_loader, network, optimizer, criterion, hparams, file_path):\n",
    "    network.train()\n",
    "    device = hparams['device']\n",
    "    network.to(device)\n",
    "    avg_loss = 0\n",
    "    with open(file_path, 'a') as file:\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if batch_idx % hparams['log_interval'] == 0:\n",
    "                log_str = (f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                           f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\\n')\n",
    "                file.write(log_str)\n",
    "                print(log_str, end='')  # print without adding an extra new line\n",
    "    return avg_loss / len(train_loader)\n",
    "\n",
    "def validation_epoch(validation_loader, network, hparams, file_path):\n",
    "    network.eval()\n",
    "    device = hparams['device']\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(), open(file_path, 'a') as file:\n",
    "        for data, target in validation_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = network(data)\n",
    "            validation_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            correct += correct_predictions(output, target)\n",
    "        validation_loss /= len(validation_loader.dataset)\n",
    "        test_acc = 100. * correct / len(validation_loader.dataset)\n",
    "        log_str = (f'\\nTest set: Average loss: {validation_loss:.4f}, Accuracy: {correct}/{len(validation_loader.dataset)} '\n",
    "                   f'({test_acc:.0f}%)\\n')\n",
    "        file.write(log_str)\n",
    "        print(log_str, end='')  # print without adding an extra new line\n",
    "    return validation_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results, Training and Testing Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(train_history, val_history, metric='accuracy'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_history[metric])\n",
    "    plt.plot(val_history[metric])\n",
    "    plt.title(f'Training and Validation {metric}')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_history['loss'])\n",
    "    plt.plot(val_history['loss'])\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_results(tr_losses, te_losses, te_accs, model_name, dt_str):\n",
    "    # Plotting Training and Testing Losses\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(tr_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(te_losses, label='Testing Loss', color='red')\n",
    "    plt.title(f'Training and Testing Loss Over Epochs - Model: {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting Testing Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(te_accs, label='Testing Accuracy', color='green')\n",
    "    plt.title(f'Testing Accuracy Over Epochs - Model: {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f\"{model_name}_{dt_str}_results.png\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_true, y_preds, class_labels):\n",
    "    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds)).T\n",
    "    results.rename(columns={0: 'Precision',\n",
    "                           1: 'Recall',\n",
    "                           2: 'F-Score',\n",
    "                           3: 'Support'}, inplace=True)\n",
    "    \n",
    "    conf_mat = pd.DataFrame(confusion_matrix(y_true, y_preds), \n",
    "                            columns=class_labels,\n",
    "                            index=class_labels)\n",
    "\n",
    "    f2 = fbeta_score(y_true, y_preds, beta=2, average='micro')\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Global F2 Score: {f2}\")\n",
    "    return results, conf_mat\n",
    "\n",
    "def plot_confusion_matrix(conf_mat):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap=sns.color_palette(\"icefire\", as_cmap=True), xticklabels=conf_mat.columns, yticklabels=conf_mat.index)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(images, y_true, y_preds, class_indices, num_samples=20):\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i, idx in enumerate(np.random.choice(len(images), size=num_samples, replace=False)):\n",
    "        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])\n",
    "        # Convert from PyTorch format (C, H, W) to image format (H, W, C)\n",
    "        ax.imshow(images[idx].permute(1, 2, 0).cpu().numpy())\n",
    "        pred_idx = y_preds[idx]\n",
    "        true_idx = y_true[idx]\n",
    "        \n",
    "        # Set title with predicted and true labels\n",
    "        ax.set_title(f\"{class_indices[pred_idx]}\\n(True: {class_indices[true_idx]})\", \n",
    "                     color=(\"green\" if pred_idx == true_idx else \"red\"))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting-up Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'batch_size': 128,\n",
    "    'num_epochs': 15,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 0.001,\n",
    "    'log_interval': 10,\n",
    "    'device': device,\n",
    "    'num_classes': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Overview of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./data/EuroSAT_RGB\"\n",
    "\n",
    "LABELS = os.listdir(DATASET)\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot class distributions of whole dataset\n",
    "counts = {}\n",
    "\n",
    "for l in LABELS:\n",
    "    counts[l] = len(os.listdir(os.path.join(DATASET, l)))\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.bar(range(len(counts)), list(counts.values()), align='center', color= colors[1])\n",
    "plt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=40)\n",
    "plt.xlabel('Class Label', fontsize=13)\n",
    "plt.ylabel('Class Size', fontsize=13)\n",
    "plt.title('EUROSAT Class Distribution', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset Size: {sum(counts.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into 10 classes of land cover. Each class varies in size, so I'll have to stratify later on when splitting the data into training, testing and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [os.path.join(DATASET, l, l+'_1000.jpg') for l in LABELS]\n",
    "\n",
    "img_paths = img_paths + [os.path.join(DATASET, l, l+'_2000.jpg') for l in LABELS]\n",
    "\n",
    "def plot_sat_imgs(paths):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(20):\n",
    "        plt.subplot(4, 5, i+1, xticks=[], yticks=[])\n",
    "        img = PIL.Image.open(paths[i], 'r')\n",
    "        plt.imshow(np.asarray(img))\n",
    "        plt.title(paths[i].split('/')[-2])\n",
    "\n",
    "plot_sat_imgs(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Upon reviewing the various class previews, we observe certain commonalities and distinct contrasts among them.\n",
    "\n",
    "Classes depicting urban settings like `Highways`, `Residential` areas, and `Industrial` sites predominantly feature man-made structures and roadways.\n",
    "\n",
    "Both `AnnualCrops` and `PermanentCrops` classes display agricultural areas, characterized by straight lines marking different crop fields.\n",
    "\n",
    "In contrast, classes such as `HerbaceousVegetation`, `Pasture`, and `Forests` represent natural landscapes. `Rivers`, also a part of the natural landscape category, are somewhat more distinguishable from these other natural classes.\n",
    "\n",
    "Analyzing the imagery content might give insights into potential class confusions. For instance, a `River` image could be misidentified as a `Highway`. Similarly, an image showing a highway junction with nearby buildings might be confused for an `Industrial` area. To overcome these challenges, it's crucial to develop a classifier that can adeptly discern these subtle differences.\n",
    "\n",
    "Regarding Sentinel-2 satellite imagery, it's possible to access over 10 additional spectral bands. For instance, the `Near-Infrared Radiation (NIR)` band is available in this dataset and can be utilized to create indices that visualize the presence or absence of radiation in an image. However, this dataset lacks NIR wavelength bands, rendering this approach infeasible for our current analysis. Nonetheless, it's important to note that NIR data could offer an alternative method for tackling this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train, Validation and Test Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './data/train'\n",
    "VALID_DIR = './data/valid'\n",
    "TEST_DIR = './data/test'\n",
    "\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(VALID_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "# And open_project folder\n",
    "os.makedirs(f'../open_project/', exist_ok=True)\n",
    "\n",
    "# create class label subdirectories in train and test\n",
    "for l in LABELS:\n",
    "    os.makedirs(os.path.join(TRAIN_DIR, l), exist_ok=True)\n",
    "    os.makedirs(os.path.join(VALID_DIR, l), exist_ok=True)\n",
    "    os.makedirs(os.path.join(TEST_DIR, l), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary with image paths and labels\n",
    "data = {os.path.join(DATASET, l, img): l for l in LABELS for img in os.listdir(os.path.join(DATASET, l))}\n",
    "\n",
    "X = pd.Series(list(data.keys()))\n",
    "y = pd.get_dummies(pd.Series(data.values()))\n",
    "\n",
    "# First split: Splitting into training and temporary set (combining test and validation)\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=69)  # 30% for test + validation\n",
    "\n",
    "for train_idx, temp_idx in split.split(X, y):\n",
    "    train_paths = X[train_idx].tolist()\n",
    "    temp_paths = X[temp_idx].tolist()\n",
    "\n",
    "# Second split: Splitting the temporary set into test and validation\n",
    "split_temp = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=69)  # 50% of 30% -> 15% each for test and validation\n",
    "y_temp = y.iloc[temp_idx]\n",
    "\n",
    "for test_idx, val_idx in split_temp.split(pd.Series(temp_paths), y_temp):\n",
    "    test_paths = pd.Series(temp_paths).iloc[test_idx].tolist()\n",
    "    val_paths = pd.Series(temp_paths).iloc[val_idx].tolist()\n",
    "\n",
    "# Define new paths without using regex\n",
    "new_train_paths = [path.replace(DATASET, TRAIN_DIR) for path in train_paths]\n",
    "new_test_paths = [path.replace(DATASET, TEST_DIR) for path in test_paths]\n",
    "new_val_paths = [path.replace(DATASET, VALID_DIR) for path in val_paths]\n",
    "\n",
    "train_path_map = zip(train_paths, new_train_paths)\n",
    "test_path_map = zip(test_paths, new_test_paths)\n",
    "val_path_map = zip(val_paths, new_val_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncomment Code Below when Run for First Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the files\n",
    "# print(\"Moving training files..\")\n",
    "# for old_path, new_path in tqdm(train_path_map):\n",
    "#     os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "#     shutil.copy(old_path, new_path)\n",
    "\n",
    "# print(\"Moving testing files..\")\n",
    "# for old_path, new_path in tqdm(test_path_map):\n",
    "#     os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "#     shutil.copy(old_path, new_path)\n",
    "\n",
    "# print(\"Moving validation files..\")\n",
    "# for old_path, new_path in tqdm(val_path_map):\n",
    "#     os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "#     shutil.copy(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for training\n",
    "mean = [0.485, 0.456, 0.406] # Adjust as needed\n",
    "std = [0.229, 0.224, 0.225] # Adjust as needed\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(60),\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)  \n",
    "])\n",
    "\n",
    "# Define transformations for testing (only normalization)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)  \n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader for training\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "\n",
    "# Optionally create the dataset and dataloader for validation\n",
    "valid_dataset = datasets.ImageFolder(root=VALID_DIR, transform=test_transforms)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=hparams['batch_size'], shuffle=False)\n",
    "\n",
    "# Create the dataset and dataloader for testing\n",
    "test_dataset = datasets.ImageFolder(root=TEST_DIR, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hparams['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Dataset Size: {len(train_dataset)}')\n",
    "print(f'Validation Dataset Size: {len(valid_dataset)}')\n",
    "print(f'Test Dataset Size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Class indices dictionary\n",
    "class_indices = train_dataset.class_to_idx\n",
    "# Reverse the mapping to get indices to class names\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "print(class_indices)\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the first batch of images from the trainloader\n",
    "first_batch_images, _ = next(iter(train_loader))\n",
    "first_image = first_batch_images[0].unsqueeze(0).to(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch_images_np = first_batch_images.numpy()\n",
    "\n",
    "# Plot samples from the first batch\n",
    "plot_samples(first_batch_images_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUROSatCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EUROSatCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EUROSatCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # First set of convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        # Second set of convolutional layers\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2) \n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        # Third set of convolutional layers\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.relu5 = nn.LeakyReLU()\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.relu6 = nn.LeakyReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # output size: 8x8\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)  # First FC layer\n",
    "        self.relu7 = nn.LeakyReLU()\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 128)  # New additional FC layer\n",
    "        self.relu8 = nn.LeakyReLU()\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, self.num_classes)  # Final classification layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First set of layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # Second set of layers\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Third set of layers\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu8(x)\n",
    "        x = self.dropout5(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Instatiating Specific Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(cnn_base, num_classes, file_path, fine_tune=None):\n",
    "    # Choose the base model and modify the classifier\n",
    "    if cnn_base in ['ResNet50', 'ResNet152V2']:\n",
    "        if cnn_base == 'ResNet50':\n",
    "            model = models.resnet50(pretrained=True)\n",
    "        elif cnn_base == 'ResNet152V2':\n",
    "            model = models.resnet152(pretrained=True)\n",
    "        else:\n",
    "            print(\"Wrong CNN base\")\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif cnn_base in ['VGG16', 'VGG19']:\n",
    "        if cnn_base == 'VGG16':\n",
    "            model = models.vgg16(pretrained=True)\n",
    "        else:  # VGG19\n",
    "            model = models.vgg19(pretrained=True)\n",
    "\n",
    "        # Modify the classifier part of VGG\n",
    "        num_ftrs = 512 * 7 * 7  # this is 25088 for 64x64 input images\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "    elif cnn_base == \"EUROSatCNN\":\n",
    "        model = EUROSatCNN(num_classes)\n",
    "\n",
    "    # Set the fine-tuning\n",
    "    if fine_tune is not None:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in list(model.parameters())[fine_tune:]:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Get the current datetime\n",
    "    dt = datetime.now()\n",
    "\n",
    "    # Format the datetime as a string in the specified format: year_month_day_hour_minute\n",
    "    str_dt = dt.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    \n",
    "    file_path = os.path.join(file_path, f'architecture_{str_dt}.txt')\n",
    "    \n",
    "    total_params, trainable_params, non_trainable_params = count_parameters(model)\n",
    "    \n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write('-------------------------------------------------------------------\\n')\n",
    "        file.write(f'{(model)}\\n')\n",
    "        file.write('-------------------------------------------------------------------\\n')\n",
    "        file.write(f'Total parameters in the model: {total_params}\\n')\n",
    "        file.write(f'Trainable parameters in the model: {trainable_params}\\n')\n",
    "        file.write(f'NON-Trainable parameters in the model: {non_trainable_params}\\n')\n",
    "        file.write('-------------------------------------------------------------------\\n')\n",
    "\n",
    "    return model, str_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(network, nework_name, model_folder, str_dt):\n",
    "    \n",
    "    model_path = os.path.join(model_folder, f'best_model_{str_dt}.pth')\n",
    "    \n",
    "    train_log_path = os.path.join(model_folder, f'training_log_{str_dt}.txt')\n",
    "    valid_log_path = os.path.join(model_folder, f'validation_log_{str_dt}_.txt')\n",
    "    \n",
    "    # Initialize variables for Early Stopping and Model Checkpoint\n",
    "    best_val_accuracy = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 10  # For early stopping\n",
    "    \n",
    "\n",
    "    # Define the optimizer with or without L2 regularization\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, network.parameters()), lr=hparams['learning_rate'], weight_decay=hparams['weight_decay'])\n",
    "\n",
    "    # Define the criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize ReduceLROnPlateau scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, min_lr=0.001)\n",
    "\n",
    "    early_stopping_triggered = False\n",
    "\n",
    "\n",
    "    # Training and validation loop\n",
    "    tr_losses, te_losses, te_accs = [], [], []\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, hparams['num_epochs'] + 1):\n",
    "        train_loss = train_epoch(epoch, train_loader, network, optimizer, criterion, hparams, train_log_path)\n",
    "        tr_losses.append(train_loss)\n",
    "        test_loss, test_acc = validation_epoch(valid_loader, network, hparams, valid_log_path)\n",
    "        te_losses.append(test_loss)\n",
    "        te_accs.append(te_accs)\n",
    "\n",
    "        # Model Checkpoint\n",
    "        if test_acc > best_val_accuracy:\n",
    "            best_val_accuracy = test_acc\n",
    "            torch.save(network.state_dict(), model_path)\n",
    "            print(f\"Checkpoint saved at {model_path}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve == patience:\n",
    "            print(\"Early stopping triggered. Exiting training loop.\")\n",
    "            early_stopping_triggered = True\n",
    "            break\n",
    "\n",
    "        # Learning Rate Scheduler Step\n",
    "        scheduler.step(test_acc)\n",
    "\n",
    "    if not early_stopping_triggered:\n",
    "        print(\"Completed training for {} epochs\".format(hparams['num_epochs']))\n",
    "    \n",
    "    # Stop the timer\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Convert elapsed time to minutes and seconds\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time % 60)\n",
    "\n",
    "    print(f'Total Training Time: {elapsed_mins}m {elapsed_secs}s')\n",
    "    \n",
    "    plot_and_save_results(tr_losses, te_losses, te_accs, nework_name)\n",
    "    \n",
    "    return tr_losses, te_losses, te_accs, nework_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 No Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_folder = '../open_project/vgg16_no_fine_tune_architecture'\n",
    "# os.makedirs(model_folder, exist_ok=True)\n",
    "# vgg16_no_fine_tune, str_dt = compile_model('VGG16', hparams['num_classes'], model_folder, fine_tune=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO WAY THIS RUN ON MY LAPTOP\n",
    "# vgg16_no_fine_tune_tr_losses, vgg16_no_fine_tune_te_losses, vgg16_no_fine_tune_te_accs, vgg16_no_fine_tune_nework_name = training_process(vgg16_no_fine_tune, \"vgg16_no_fine_tune\", str_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUROSatCNN No Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = '../open_project/EUROSatCNN_no_fine_tune'\n",
    "os.makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EUROSatCNN_no_fine_tune, str_dt = compile_model('EUROSatCNN', hparams['num_classes'], model_folder, fine_tune=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_losses, te_losses, te_accs, nework_name = training_process(EUROSatCNN_no_fine_tune, \"EUROSatCNN_no_fine_tune\", model_folder, str_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EUROSatCNN(hparams['num_classes'])\n",
    "# model_path = \"EUROSatCNN_no_fine_tune_model_best.pth\"\n",
    "# model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "# model.eval()\n",
    "\n",
    "model = EUROSatCNN_no_fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch of images and their labels from the test_loader\n",
    "images, labels = next(iter(test_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Predict labels\n",
    "model.eval()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map predicted and true labels back to class names\n",
    "predicted_labels = [idx_to_class[idx] for idx in predicted.cpu().numpy()]\n",
    "true_labels = [idx_to_class[idx] for idx in labels.cpu().numpy()]\n",
    "\n",
    "# Visualize predictions\n",
    "plot_predictions(images, true_labels, predicted_labels, class_indices, num_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store true and predicted labels\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "# Predict labels for the entire test dataset\n",
    "model.eval()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and labels to the lists\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can pass all_labels and all_predictions to the display_results function\n",
    "prf, conf_mat = display_results(all_labels, all_predictions, class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to plot the confusion matrix\n",
    "plot_confusion_matrix(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml-block3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
